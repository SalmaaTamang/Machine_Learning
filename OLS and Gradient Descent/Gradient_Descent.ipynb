{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03364420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6315eb18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y = make_regression(n_samples=100, n_features=1, n_informative=1, n_targets=1,noise=20)\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ded95e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938a4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deba15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 53.405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor:\n",
    "    def __init__(self,learning_rate,epochs):\n",
    "        self.m = m\n",
    "        self.b = 0\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "    def fit(self,x,y):\n",
    "        for i in range(self.epochs):\n",
    "            loss_slope = -2*np.sum(y - self.m*x.ravel() -self.b)\n",
    "            self.b = self.b -(self.lr*loss_slope)\n",
    "            print(loss_slope,self.b)\n",
    "        print(self.b)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd = Regressor(0.001,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c019ca3",
   "metadata": {},
   "source": [
    "##Learning rate effect\n",
    "The gradient Descent is too sensitive to learning rate.\n",
    "If learning rate is too small then small steps toward soln and take lot of time to reach soln.\n",
    "If learning rate is too high then we cannot reach to the soln and it diverges from the soln.\n",
    "So the learning ratevmust be appropriate val depending upon the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294891f1",
   "metadata": {},
   "source": [
    "##Why Gradient Descent is  Universaltity? \n",
    "Gradient Descent is an optimization techniques that can be used with other algos as well.If \n",
    "loss fxn is differential of that algos since slope is obtained by differentating loss fxn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdbfacd",
   "metadata": {},
   "source": [
    "##calculating both coefficient=m and intercept=b\n",
    "steps:\n",
    "1.Initalize the both value of m and b randomly\n",
    "2.Decide no of epochs and learnig rate\n",
    "3.calculate val of \n",
    "b_new = b_old -lr.slope at b_old(slope with respect to b keepimg m constant)\n",
    "m_new = m-old - lr.slope at m-old (slope with respect to m keepnig b constant)\n",
    "slope wrt to b = -2 *summation from i=0 to n(yi-mxi-b)\n",
    "slope wrt to m = -2*summation form i=0 to n((yi-mxi-b)*xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66172a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDRegressor:\n",
    "    def __init__(self,learning_rate,epochs):\n",
    "        self.m = 100\n",
    "        self.b = 0\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self,x,y):\n",
    "        #calculating slope wrt to b and m and updating there values\n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            loss_slope_wrt_b = -2 *np.sum(y - self.m*x.ravel()-self.b)\n",
    "            loss_slope_wrt_m = -2 *np.sum((y - self.m*x.ravel()-self.b)*x.ravel())\n",
    "            self.b = self.b -(self.lr*loss_slope_wrt_b)\n",
    "            self.m = self.m -(self.lr*loss_slope_wrt_m)\n",
    "        print(self.m,self.b) \n",
    "        \n",
    "    def predict(self,x):   \n",
    "        \n",
    "            return self.m*x +self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38aec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_reg=GDRegressor(0.001,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b80acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_reg.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1869fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_reg.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c343828b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
